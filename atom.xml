<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>徐斌斌的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xvbinbin.xyz/"/>
  <updated>2021-12-12T16:46:15.734Z</updated>
  <id>https://xvbinbin.xyz/</id>
  
  <author>
    <name>徐斌斌</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CS224N Lecture 11 - Question Answering</title>
    <link href="https://xvbinbin.xyz/2021/12/12/cs224n-lecture-11-question-answering/"/>
    <id>https://xvbinbin.xyz/2021/12/12/cs224n-lecture-11-question-answering/</id>
    <published>2021-12-12T14:55:39.000Z</published>
    <updated>2021-12-12T16:46:15.734Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;30：44&lt;br&gt;QA系统有两种分类，一种是基于LSTM的attention模型，一种是在bert模型基础上微调。&lt;/p&gt;
&lt;h1 id=&quot;BiDAFF：the-Bidirectional-Attention-Flow-model&quot;&gt;&lt;a
        
      
    
    </summary>
    
      <category term="深度学习" scheme="https://xvbinbin.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="nlp" scheme="https://xvbinbin.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/nlp/"/>
    
    
      <category term="nlp" scheme="https://xvbinbin.xyz/tags/nlp/"/>
    
      <category term="cs224n" scheme="https://xvbinbin.xyz/tags/cs224n/"/>
    
      <category term="深度学习" scheme="https://xvbinbin.xyz/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="学习笔记" scheme="https://xvbinbin.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Attention Is All Your Need</title>
    <link href="https://xvbinbin.xyz/2021/12/11/attention-is-all-your-need/"/>
    <id>https://xvbinbin.xyz/2021/12/11/attention-is-all-your-need/</id>
    <published>2021-12-10T17:40:36.000Z</published>
    <updated>2021-12-12T14:53:31.426Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;论文地址:&lt;a href=&quot;https://arxiv.org/abs/1706.03762v5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Attention Is All Your Need&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;介绍&quot;&gt;&lt;a
        
      
    
    </summary>
    
      <category term="深度学习" scheme="https://xvbinbin.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="nlp" scheme="https://xvbinbin.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/nlp/"/>
    
    
      <category term="nlp" scheme="https://xvbinbin.xyz/tags/nlp/"/>
    
      <category term="cs224n" scheme="https://xvbinbin.xyz/tags/cs224n/"/>
    
      <category term="深度学习" scheme="https://xvbinbin.xyz/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文研读" scheme="https://xvbinbin.xyz/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/"/>
    
      <category term="Transformer" scheme="https://xvbinbin.xyz/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>CS224N attention学习笔记</title>
    <link href="https://xvbinbin.xyz/2021/12/08/cs224n-attention-xue-xi-bi-ji/"/>
    <id>https://xvbinbin.xyz/2021/12/08/cs224n-attention-xue-xi-bi-ji/</id>
    <published>2021-12-08T08:33:54.000Z</published>
    <updated>2021-12-10T17:42:07.664Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;&lt;img src=&quot;1.png&quot; alt&gt;&lt;br&gt;Attention&lt;/p&gt;
&lt;p&gt;• 常规Seq2Seq的RNN网络，存在imformation
        
      
    
    </summary>
    
      <category term="深度学习" scheme="https://xvbinbin.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="nlp" scheme="https://xvbinbin.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/nlp/"/>
    
    
      <category term="nlp" scheme="https://xvbinbin.xyz/tags/nlp/"/>
    
      <category term="cs224n" scheme="https://xvbinbin.xyz/tags/cs224n/"/>
    
      <category term="深度学习" scheme="https://xvbinbin.xyz/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="学习笔记" scheme="https://xvbinbin.xyz/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://xvbinbin.xyz/2021/12/08/hello-world/"/>
    <id>https://xvbinbin.xyz/2021/12/08/hello-world/</id>
    <published>2021-12-08T08:07:49.082Z</published>
    <updated>2021-12-08T08:07:49.082Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a
        
      
    
    </summary>
    
    
  </entry>
  
</feed>
